{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import random\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "def get_train_valid_idx(sample_num):\n",
    "    \"\"\"\n",
    "    Obtain the indices for the training set and validation set according to an 8:2 ratio\n",
    "    \"\"\"\n",
    "    train_idx = []\n",
    "    valid_idx = []\n",
    "    random_idx = list(range(sample_num))\n",
    "    random.shuffle(random_idx)\n",
    "    avg_group_count = 10\n",
    "    step = int(len(random_idx)/avg_group_count)\n",
    "    random_idx_group = [random_idx[i:i+step] for i in range(0,len(random_idx),step)]\n",
    "    for i in range(8):\n",
    "        train_idx.extend(random_idx_group[i])\n",
    "    for i in range(8,len(random_idx_group)):\n",
    "        valid_idx.extend(random_idx_group[i])\n",
    "    return {'train':train_idx,'valid':valid_idx}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate train set and validation set\n",
    "\n",
    "Generate and save the training and validation datasets to the \"train_valid_csv\" directory based on the \"fa_diff_len\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_dir = \"./fa_diff_len/\"\n",
    "train_data_dir = \"./train_valid_csv\"\n",
    "\n",
    "os.makedirs(train_data_dir,exist_ok=True)\n",
    "for specie in ['human','pig']:\n",
    "    if specie=='pig':\n",
    "        extend_lens = [256,512,1024,2048]\n",
    "        cre_types = ['e1','e4e5','e10','e1_e10','e1_e4e5_e10']\n",
    "    elif specie==\"human\":\n",
    "        extend_lens = [256,512,1024,2048]\n",
    "        cre_types = ['promoter','enhancer','promoter_enhancer']\n",
    "    for extend_len in extend_lens:\n",
    "        for cre_type in cre_types:\n",
    "            train_dir = f\"{cre_type}_{extend_len*2+1}\"\n",
    "            absolute_dir = os.path.join(train_data_dir,specie,train_dir)\n",
    "            os.makedirs(absolute_dir)\n",
    "            for train_valid in ['train','valid']:\n",
    "                output_csv = \"train.csv\" if train_valid==\"train\" else \"dev.csv\"\n",
    "                csv_path = os.path.join(absolute_dir,output_csv)\n",
    "                seqs = {}\n",
    "                seqs_labels = {}\n",
    "                for pos_neg in ['positive','negative']:\n",
    "                    seq_label = 1 if pos_neg==\"positive\" else 0\n",
    "                    fafile = os.path.join(fasta_dir,specie,f\"{cre_type}_len_{extend_len*2+1}_{train_valid}_{pos_neg}.fa\")\n",
    "                    fa = pysam.FastaFile(fafile)\n",
    "                    seqs[pos_neg] = [fa.fetch(rederence) for rederence in fa.references]\n",
    "                    seqs_labels[pos_neg] = [(seq,seq_label) for seq in seqs[pos_neg]]\n",
    "                merge_sample = seqs_labels['positive']+seqs_labels['negative']\n",
    "                random.shuffle(merge_sample)\n",
    "                df_csv = pd.DataFrame(merge_sample)\n",
    "                df_csv.columns = ['sequence','label']\n",
    "                df_csv.to_csv(csv_path,sep=\",\",index=None)\n",
    "                if train_valid==\"valid\":\n",
    "                    output_csv = \"test.csv\"\n",
    "                    csv_path = os.path.join(absolute_dir,output_csv)\n",
    "                    df_csv.to_csv(csv_path,sep=\",\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate model fine-tuning script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmd(CUDA_VISIBLE_DEVICES,MODEL_PATH,DATA_PATH,RUN_NAME,MAX_LENGTH,LR,save_steps,OUTPUT_DIR,eval_steps,logging_steps):\n",
    "    bashFile = f\"\"\"\n",
    "export CUDA_VISIBLE_DEVICES={CUDA_VISIBLE_DEVICES}\n",
    "python /data2/zyd_workspace/2024_12_multi_species_models/dnabert-2/DNABERT_2/finetune/train.py \\\n",
    "--model_name_or_path {MODEL_PATH} \\\n",
    "--data_path {DATA_PATH} \\\n",
    "--kmer -1 \\\n",
    "--run_name {RUN_NAME} \\\n",
    "--model_max_length {MAX_LENGTH} \\\n",
    "--per_device_train_batch_size 16 \\\n",
    "--per_device_eval_batch_size 16 \\\n",
    "--gradient_accumulation_steps 1 \\\n",
    "--learning_rate {LR} \\\n",
    "--num_train_epochs 20 \\\n",
    "--fp16 \\\n",
    "--save_steps {save_steps} \\\n",
    "--output_dir {OUTPUT_DIR} \\\n",
    "--evaluation_strategy steps \\\n",
    "--eval_steps {eval_steps} \\\n",
    "--warmup_steps 50 \\\n",
    "--logging_steps {logging_steps} \\\n",
    "--overwrite_output_dir True \\\n",
    "--log_level info \\\n",
    "--find_unused_parameters False \\\n",
    "--save_total_limit 20\n",
    "\"\"\"\n",
    "    return bashFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 16\n",
    "model_path = \"/data2/zyd_workspace/2024_12_multi_species_models/dnabert-2/DNABERT-2-117M\"\n",
    "train_data_dir = \"./train_valid_csv\"\n",
    "train_output_dir = \"./train_output\"\n",
    "os.makedirs(train_output_dir,exist_ok=True)\n",
    "all_train_cmd = []\n",
    "for specie in ['human','pig']:\n",
    "    if specie=='pig':\n",
    "        extend_lens = [256,512,1024,2048]\n",
    "        cre_types = ['e1','e4e5','e10','e1_e10','e1_e4e5_e10']\n",
    "    elif specie==\"human\":\n",
    "        extend_lens =[256,512,1024,2048]\n",
    "        cre_types = ['promoter','enhancer','promoter_enhancer']\n",
    "    for extend_len in extend_lens:\n",
    "        for cre_type in cre_types:\n",
    "            train_dir = f\"{cre_type}_{extend_len*2+1}\"\n",
    "            run_name = f\"{specie}_{train_dir}\"\n",
    "            data_path = os.path.join(train_data_dir,specie,train_dir)\n",
    "            output_path = os.path.join(train_output_dir,specie,train_dir)\n",
    "            df_train_csv = pd.read_csv(os.path.join(data_path,\"train.csv\"),sep=\"\\t\")\n",
    "            loggin_steps = int(df_train_csv.shape[0]/batch_size)\n",
    "            save_steps = int(df_train_csv.shape[0]/batch_size)\n",
    "            eval_steps = save_steps\n",
    "            loggin_steps = save_steps\n",
    "            max_len = int(0.25*(extend_len*2+1))+1\n",
    "            cuda_divice = 1 if extend_len<=512 else 0\n",
    "            all_train_cmd.append(get_cmd(CUDA_VISIBLE_DEVICES=cuda_divice,MODEL_PATH=model_path,DATA_PATH=data_path,RUN_NAME=run_name,MAX_LENGTH=max_len,LR=3e-5,save_steps=save_steps,OUTPUT_DIR=output_path,eval_steps=eval_steps,logging_steps=save_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_4090_1 = open(\"./train_4090_1.sh\",\"w\")\n",
    "f_4090_2 = open(\"./train_4090_2.sh\",\"w\")\n",
    "for i in all_train_cmd:\n",
    "    if \"CUDA_VISIBLE_DEVICES=0\" in i:\n",
    "        f_4090_1.write(f\"{i}\\n\")\n",
    "    else:\n",
    "        f_4090_2.write(f\"{i}\\n\")\n",
    "f_4090_1.close()\n",
    "f_4090_2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
