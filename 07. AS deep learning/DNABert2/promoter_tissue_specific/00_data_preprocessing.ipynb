{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pysam\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_train_valid_idx(sample_num):\n",
    "    \"\"\"\n",
    "    Obtain the indices for the training set and validation set according to an 8:2 ratio\n",
    "    \"\"\"\n",
    "    train_idx = []\n",
    "    valid_idx = []\n",
    "    random_idx = list(range(sample_num))\n",
    "    random.shuffle(random_idx)\n",
    "    avg_group_count = 10\n",
    "    step = int(len(random_idx)/avg_group_count)\n",
    "    random_idx_group = [random_idx[i:i+step] for i in range(0,len(random_idx),step)]\n",
    "    for i in range(8):\n",
    "        train_idx.extend(random_idx_group[i])\n",
    "    for i in range(8,len(random_idx_group)):\n",
    "        valid_idx.extend(random_idx_group[i])\n",
    "    return {'train':train_idx,'valid':valid_idx}\n",
    "\n",
    "\n",
    "tissues = ['Skeletal_Muscle','Liver','Adipose','Heart','Spleen']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate train set and validation set\n",
    "\n",
    "Generate and save the training and validation datasets to the \"train_valid_csv\" directory based on the \"fa_diff_len\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_dir = \"./fa_diff_len\"\n",
    "\n",
    "for snp_dir in ['pig_e1','pig_e10',\"pig_e1_e10\",'human_promoter']:\n",
    "    for extend_len in [512]:\n",
    "        for tissue in tissues:\n",
    "            fa_positive = os.path.join(fasta_dir,snp_dir,f\"{tissue}_{extend_len*2+1}_positive.fa\")\n",
    "            fa_positive = pysam.FastaFile(fa_positive)\n",
    "            fa_negative = os.path.join(fasta_dir,snp_dir,f\"{tissue}_{extend_len*2+1}_negative.fa\")\n",
    "            fa_negative = pysam.FastaFile(fa_negative)\n",
    "            group_idx = get_train_valid_idx(len(fa_positive.references))\n",
    "            seq_pos_train = [ (fa_positive.fetch(fa_positive.references[i]),1) for i in group_idx['train']]\n",
    "            seq_pos_valid = [ (fa_positive.fetch(fa_positive.references[i]),1) for i in group_idx['valid']]\n",
    "            \n",
    "            group_idx = get_train_valid_idx(len(fa_negative.references))\n",
    "            seq_neg_train = [ (fa_negative.fetch(fa_negative.references[i]),0) for i in group_idx['train']]\n",
    "            seq_neg_valid = [ (fa_negative.fetch(fa_negative.references[i]),0) for i in group_idx['valid']]\n",
    "            \n",
    "            all_seq_train = pd.DataFrame(seq_pos_train+seq_neg_train)\n",
    "            all_seq_valid = pd.DataFrame(seq_pos_valid+seq_neg_valid)\n",
    "            all_seq_train.columns = ['sequence','label']\n",
    "            all_seq_valid.columns = ['sequence','label']\n",
    "            all_seq_train = all_seq_train.sample(frac=1)\n",
    "            all_seq_valid = all_seq_valid.sample(frac=1)\n",
    "            save_dir = f\"./train_valid_csv/{snp_dir}_{extend_len*2+1}/{tissue}\"\n",
    "            os.makedirs(save_dir,exist_ok=True)\n",
    "            train_csv = f\"{save_dir}/train.csv\"\n",
    "            valid_csv = f\"{save_dir}/dev.csv\"\n",
    "            test_csv = f\"{save_dir}/test.csv\"\n",
    "            all_seq_train.to_csv(train_csv,index=None)\n",
    "            all_seq_valid.to_csv(valid_csv,index=None)\n",
    "            all_seq_valid.to_csv(test_csv,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate model fine-tuning script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmd(CUDA_VISIBLE_DEVICES,MODEL_PATH,DATA_PATH,RUN_NAME,MAX_LENGTH,LR,save_steps,OUTPUT_DIR,eval_steps,logging_steps):\n",
    "    bashFile = f\"\"\"\n",
    "export CUDA_VISIBLE_DEVICES={CUDA_VISIBLE_DEVICES}\n",
    "python /data2/zyd_workspace/2024_12_multi_species_models/dnabert-2/DNABERT_2/finetune/train.py \\\n",
    "--model_name_or_path {MODEL_PATH} \\\n",
    "--data_path {DATA_PATH} \\\n",
    "--kmer -1 \\\n",
    "--run_name {RUN_NAME} \\\n",
    "--model_max_length {MAX_LENGTH} \\\n",
    "--per_device_train_batch_size 16 \\\n",
    "--per_device_eval_batch_size 16 \\\n",
    "--gradient_accumulation_steps 1 \\\n",
    "--learning_rate {LR} \\\n",
    "--num_train_epochs 20 \\\n",
    "--fp16 \\\n",
    "--save_steps {save_steps} \\\n",
    "--output_dir {OUTPUT_DIR} \\\n",
    "--evaluation_strategy steps \\\n",
    "--eval_steps {eval_steps} \\\n",
    "--warmup_steps 50 \\\n",
    "--logging_steps {logging_steps} \\\n",
    "--overwrite_output_dir True \\\n",
    "--log_level info \\\n",
    "--find_unused_parameters False \\\n",
    "--save_total_limit 20\n",
    "\"\"\"\n",
    "    return bashFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_lens = [512]\n",
    "batch_size = 16\n",
    "model_path = \"/data2/zyd_workspace/2024_12_multi_species_models/dnabert-2/DNABERT-2-117M\"\n",
    "train_data_dir = \"./train_valid_csv\"\n",
    "train_output_dir = \"./train_output\"\n",
    "all_train_cmd = []\n",
    "for species in ['human','pig']:\n",
    "    if species=='pig':\n",
    "        cre_types = ['e1_e10','e1','e10']\n",
    "    elif species==\"human\":\n",
    "        cre_types = ['promoter']\n",
    "    for extend_len in extend_lens:\n",
    "        for cre_type in cre_types:\n",
    "                train_dir = f\"{species}_{cre_type}_{extend_len*2+1}\"\n",
    "                for tissue in tissues:\n",
    "                    run_name = f\"{species}_{cre_type}_{extend_len*2+1}_{tissue}\"\n",
    "                    data_path = os.path.join(train_data_dir,train_dir,tissue)\n",
    "                    output_path = os.path.join(train_output_dir,train_dir,tissue)\n",
    "                    df_train_csv = pd.read_csv(os.path.join(data_path,\"train.csv\"),sep=\"\\t\")\n",
    "                    loggin_steps = int(df_train_csv.shape[0]/batch_size)\n",
    "                    save_steps = int(df_train_csv.shape[0]/batch_size)\n",
    "                    eval_steps = save_steps\n",
    "                    loggin_steps = save_steps\n",
    "                    max_len = int(0.25*(extend_len*2+1))+1\n",
    "                    cuda_divice = 1 if extend_len<512 else 0\n",
    "                    all_train_cmd.append(get_cmd(CUDA_VISIBLE_DEVICES=cuda_divice,MODEL_PATH=model_path,DATA_PATH=data_path,RUN_NAME=run_name,MAX_LENGTH=max_len,LR=3e-5,save_steps=save_steps,OUTPUT_DIR=output_path,eval_steps=eval_steps,logging_steps=save_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./train.sh\",'w') as f:\n",
    "    f.write('\\n'.join(all_train_cmd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
